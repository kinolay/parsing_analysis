# parsing_analysis



1) Файл "parsing": считывание таблицы с сайта https://rosseti-lenenergo.ru/planned_work/, фильтр по времени - период текущей недели (текущий день + 6 дней), заметил что данные отсортированны по дате (от будующих к прошедшим) и чтобы экономить ресурсы сделал возможность выбрать предельную страницу  сбора данных. Настройку автоматического запуска скрипта по расписанию можно сделать с помощью планировщика задач в linux либо бесконечный цикл в коде и модуль schedule. Но для того чтобы экономить ресурсы и делать правки в коде, лучше сделать через планировщик задач. В командной строке написать "crontab -e", добавить следующую строку в файл crontab: 0 9 * * 2 /usr/bin/python3/путь_к_вашему_скрипту/parsing.py. И теперь парсинг будет осуществляться каждый вторник в 9:00
 
2) Работа с данными, файл "work_with_data": разбиение столбца Улица на отдельные адреса. Геокод адресов через https://petersburg.ru/mainPortal/api_services/view/2223 и сохранение building_id найденных зданий. Запись результата в csv файл
     
3) Анализ и визуализация данных
